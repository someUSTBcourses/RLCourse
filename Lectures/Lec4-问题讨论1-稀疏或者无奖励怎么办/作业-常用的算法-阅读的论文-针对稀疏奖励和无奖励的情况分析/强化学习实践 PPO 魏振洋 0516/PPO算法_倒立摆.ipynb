{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1、PG（Policy Gradient）算法回顾**\n",
    "\n",
    "在PG算法中，我们的Agent又被称为Actor，Actor对于一个特定的任务，都有自己的一个策略π，策略π通常用一个神经网络表示，其参数为θ。从一个特定的状态state出发，一直到任务的结束，被称为一个完整的eposide，在每一步，我们都能获得一个奖励r，一个完整的任务所获得的最终奖励被称为R。这样，一个有T个时刻的eposide，Actor不断与环境交互，形成如下的序列τ：\n",
    "\n",
    "![PG算法序列τ](images/PG算法序列τ.png)\n",
    "\n",
    "这样一个序列τ是不确定的，因为Actor在不同state下所采取的action可能是不同的，一个序列τ发生的概率为：\n",
    "\n",
    "$\\begin{array}{l}p_\\theta(\\tau)\\\\ =p(s_1)p_\\theta(a_1|s_1)p(s_2|s_1,a_1)p_\\theta(a_2|s_2)p(s_3|s_2,a_2)\\cdots\\\\ =p(s_1)\\prod_{t=1}^T p_\\theta(a_t|s_t)p(s_{t+1}|s_t,a_t)\\\\ \\end{array}$\n",
    "\n",
    "序列τ所获得的奖励为每个阶段所得到的奖励的和，称为R(τ)。因此，在Actor的策略为π的情况下，所能获得的期望奖励为：\n",
    "\n",
    "$\\bar{R}_\\theta=\\sum_\\tau R(\\tau)p_\\theta(\\tau)=E_{\\tau\\sim p_\\theta(\\tau)}[R(\\tau)]$\n",
    "\n",
    "而我们的期望是调整Actor的策略π，使得期望奖励最大化，于是我们有了策略梯度的方法，既然我们的期望函数已经有了，我们只要使用梯度提升的方法更新我们的网络参数θ（即更新策略π）就好了，所以问题的重点变为了求参数的梯度。梯度的求解过程如下：\n",
    "\n",
    "![img](images/PG梯度求解.png)\n",
    "\n",
    "上面的过程中，我们首先利用log函数求导的特点进行转化，随后用N次采样的平均值来近似期望，最后，我们将pθ展开，将与θ无关的项去掉，即得到了最终的结果。\n",
    "\n",
    "所以，一个PG方法的完整过程如下：\n",
    "\n",
    "![img](images/PG流程.png)\n",
    "\n",
    "我们首先采集数据，然后基于前面得到的梯度提升的式子更新参数，随后再根据更新后的策略再采集数据，再更新参数，如此循环进行。注意到图中的大红字only used once，因为在更新参数后，我们的策略已经变了，而先前的数据是基于更新参数前的策略得到的。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2、PPO算法原理简介**\n",
    "\n",
    "PG方法一个很大的缺点就是参数更新慢，因为我们每更新一次参数都需要进行重新的采样，这其实是中on-policy的策略，即我们想要训练的agent和与环境进行交互的agent是同一个agent；与之对应的就是off-policy的策略，即想要训练的agent和与环境进行交互的agent不是同一个agent，简单来说，就是拿别人的经验来训练自己。举个打游戏的例子，如果你是通过自己玩竞技游戏来不断提升自己的水平，那么就是on-policy的，如果是通过看别人打游戏来学习经验，那么就是off-policy的。\n",
    "\n",
    "那么为了提升我们的训练速度，让采样到的数据可以重复使用，我们可以将on-policy的方式转换为off-policy的方式。即我们的训练数据通过另一个Actor（对应的网络参数为θ'得到。这要怎么做呢？通过下面的思路：\n",
    "\n",
    "![img](images/importance_sampling.png)\n",
    "\n",
    "通过上述公式，我们可以认为两者的期望是相同的，但方差是否也相同呢？这里用到概率论中常用的公式，计算结果如下：\n",
    "\n",
    "![importance sampling方差](images/importance_sampling方差.png)\n",
    "\n",
    "所以问题就出现了，如果采样较少，importance sampling方法可能导致方差差异较大，通过这种方式，我们的p(x)和q(x)的分布不能差别太大，否则需要进行非常多次的采样，才能得到近似的结果，下图就是两者分布相差较大时出现的问题：\n",
    "\n",
    "![img](images/importance sampling问题.png)\n",
    "\n",
    "如上图所示，很显然，在x服从p(x)分布时，f(x)的期望为负，此时我们从q(x)中来采样少数的x，那么我们采样到的x很有可能都分布在右半部分，此时f(x)大于0，我们很容易得到f(x)的期望为正的结论，这就会出现问题，因此需要进行大量的采样。\n",
    "\n",
    "那么此时我们想要期望奖励最大化，则变为，相较于之前的on-policy，现在变成了从$\\theta'$进行采样，且多了$\\frac{p_\\theta}{p_\\theta'}$项：\n",
    "\n",
    "![off policy](images/off_policy.png)\n",
    "\n",
    "则梯度变为：\n",
    "\n",
    "![梯度更新](images/梯度更新.png)\n",
    "\n",
    "最后一项因为我们假设两个分布不能差太远，所以认为他们是相等的，为了求解方便，我们直接划掉。此时似然函数变为：\n",
    "\n",
    "![img](https:////upload-images.jianshu.io/upload_images/4155986-294137f7a57a5986.png?imageMogr2/auto-orient/strip|imageView2/2/w/621/format/webp)\n",
    "\n",
    "由梯度变为似然函数，使用的还是这个式子：$\\nabla f(x)=f(x)\\nabla logf(x)$\n",
    "\n",
    "\n",
    "\n",
    "到这里，我们马上就要得到我们的PPO算法了。\n",
    "\n",
    "我们前面介绍了，我们希望θ和θ'不能差太远，这并不是说参数的值不能差太多，而是说，输入同样的state，网络得到的动作的概率分布不能差太远。得到动作的概率分布的相似程度，我们可以用KL散度来计算，将其加入PPO模型的似然函数中，变为：\n",
    "\n",
    "![PPO](images/PPO.png)\n",
    "\n",
    "在实际中，我们会动态改变对θ和θ'分布差异的惩罚，如果KL散度值太大，我们增加这一部分惩罚，如果小到一定值，我们就减小这一部分的惩罚，基于此，我们得到了PPO算法的过程：\n",
    "\n",
    "![img](https:////upload-images.jianshu.io/upload_images/4155986-a31ebb78f4dc906a.png?imageMogr2/auto-orient/strip|imageView2/2/w/897/format/webp)\n",
    "\n",
    "PPO的前身TRPO与PPO也是基本一致的，但是不像PPO直接把惩罚项直接放到需要优化的式子中，从而可以直接用梯度下降的方法去最大化这个式子，TRPO把KL散度当作一个constrain，希望$\\theta$和$\\theta'$的KL散度小于$\\delta$，但这个在实现中较为困难。\n",
    "\n",
    "![TRPO](images/TRPO.png)\n",
    "\n",
    "PPO算法还有另一种实现方式，不将KL散度直接放入似然函数中，而是进行一定程度的裁剪：\n",
    "\n",
    "![img](https:////upload-images.jianshu.io/upload_images/4155986-04610cbfc65b81aa.png?imageMogr2/auto-orient/strip|imageView2/2/w/927/format/webp)\n",
    "\n",
    "上图中，绿色的线代表min中的第一项，即不做任何处理，蓝色的线为第二项，如果两个分布差距太大，则进行一定程度的裁剪。最后对这两项再取min，防止了θ更新太快。\n",
    "\n",
    "PPT参考：https://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2018/Lecture/PPO%20(v3).pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3、CartPole**\n",
    "\n",
    "倒立摆问题是强化学习中的经典控制问题。Cartpole 是倒立摆问题中的一个离散控制任务。在游戏中有一个小车，上有竖着一根杆子。小车在一个光滑无摩擦的轨道上左右滑行，目的是使杆子保持竖直。如下图所示。\n",
    "![cartpole](images/cartpole.gif)\n",
    "\n",
    "Cartpole 的动作空间属于离散动作空间，有 2 个离散动作，分别是左移和右移。\n",
    "- 左移 : 0 表示让 agent 向左移动。\n",
    "- 右移 : 1 表示让 agent 向右移动。\n",
    "\n",
    "\n",
    "Cartpole 的状态空间有 4 个元素，分别是：\n",
    "- Cart Position ：小车的位置，范围是 [-4.8, 4.8] 。\n",
    "- Cart Velocity ：小车的速度，范围是 [-inf, inf] 。\n",
    "- Pole Angle ：杆的角度，范围是 [-24 deg, 24 deg] 。\n",
    "- Pole Angular Velocity ：杆的角速度，范围是 [-inf, inf] 。\n",
    "\n",
    "奖励空间\n",
    "\n",
    "每一步操作，都将获得值为 1 的奖励，直到 episode 终止（终止状态也将获得值为 1 的奖励）。\n",
    "\n",
    "终止条件\n",
    "\n",
    "Cartpole 环境每个 episode 的终止条件是遇到以下任何一种情况：\n",
    "- 杆偏移的角度超过 12 度。\n",
    "- 小车出界，通常把边界距离设置为 2.4。\n",
    "- 达到 episode 的最大 step，默认为 200。\n",
    "\n",
    "Cartpole 任务在什么情况下视为胜利\n",
    "\n",
    "当100次试验的平均 episode 奖励达到 195 以上时，视作游戏胜利。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00748571, -0.01096423,  0.01147898, -0.02036478], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# 定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            done = True\n",
    "        return state, reward, done, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saltyFish\\anaconda3\\envs\\rl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5375, 0.4625],\n",
       "         [0.5357, 0.4643]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1332],\n",
       "         [0.1797]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    "    torch.nn.Softmax(dim=1),    # 希望模型输出结果是两个动作的概率分布\n",
    ")\n",
    "\n",
    "model_td = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 1),    # 评价\n",
    ")\n",
    "\n",
    "model(torch.randn(2, 4)), model_td(torch.randn(2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# 得到一个动作\n",
    "def get_action(state):\n",
    "    state = torch.FloatTensor(state).reshape(1, 4)\n",
    "    # [1, 4] -> [1, 2]\n",
    "    prob = model(state)\n",
    "\n",
    "    # 根据概率选择一个动作\n",
    "    action = random.choices(range(2), weights=prob[0].tolist(), k=1)[0]\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "get_action([1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saltyFish\\anaconda3\\envs\\rl\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5443e-02, -3.1456e-02,  2.1062e-02,  3.8902e-02],\n",
       "         [-1.6072e-02, -2.2687e-01,  2.1840e-02,  3.3816e-01],\n",
       "         [-2.0609e-02, -3.2069e-02,  2.8604e-02,  5.2439e-02],\n",
       "         [-2.1251e-02, -2.2759e-01,  2.9652e-02,  3.5401e-01],\n",
       "         [-2.5802e-02, -3.2901e-02,  3.6732e-02,  7.0821e-02],\n",
       "         [-2.6460e-02,  1.6168e-01,  3.8149e-02, -2.1005e-01],\n",
       "         [-2.3227e-02,  3.5623e-01,  3.3948e-02, -4.9046e-01],\n",
       "         [-1.6102e-02,  1.6065e-01,  2.4139e-02, -1.8727e-01],\n",
       "         [-1.2889e-02, -3.4811e-02,  2.0393e-02,  1.1293e-01],\n",
       "         [-1.3585e-02,  1.6001e-01,  2.2652e-02, -1.7325e-01],\n",
       "         [-1.0385e-02, -3.5426e-02,  1.9187e-02,  1.2649e-01],\n",
       "         [-1.1094e-02,  1.5942e-01,  2.1716e-02, -1.6008e-01],\n",
       "         [-7.9054e-03,  3.5422e-01,  1.8515e-02, -4.4584e-01],\n",
       "         [-8.2103e-04,  1.5884e-01,  9.5981e-03, -1.4737e-01],\n",
       "         [ 2.3558e-03, -3.6417e-02,  6.6506e-03,  1.4832e-01],\n",
       "         [ 1.6275e-03, -2.3163e-01,  9.6170e-03,  4.4310e-01],\n",
       "         [-3.0052e-03, -3.6649e-02,  1.8479e-02,  1.5346e-01],\n",
       "         [-3.7382e-03,  1.5820e-01,  2.1548e-02, -1.3334e-01],\n",
       "         [-5.7411e-04, -3.7220e-02,  1.8881e-02,  1.6607e-01],\n",
       "         [-1.3185e-03, -2.3261e-01,  2.2203e-02,  4.6464e-01],\n",
       "         [-5.9707e-03, -3.7806e-02,  3.1496e-02,  1.7904e-01],\n",
       "         [-6.7268e-03,  1.5685e-01,  3.5076e-02, -1.0354e-01],\n",
       "         [-3.5898e-03,  3.5145e-01,  3.3006e-02, -3.8496e-01],\n",
       "         [ 3.4393e-03,  5.4609e-01,  2.5306e-02, -6.6705e-01],\n",
       "         [ 1.4361e-02,  7.4085e-01,  1.1965e-02, -9.5166e-01],\n",
       "         [ 2.9178e-02,  5.4557e-01, -7.0678e-03, -6.5524e-01],\n",
       "         [ 4.0090e-02,  3.5055e-01, -2.0173e-02, -3.6479e-01],\n",
       "         [ 4.7101e-02,  1.5572e-01, -2.7469e-02, -7.8539e-02],\n",
       "         [ 5.0215e-02, -3.8998e-02, -2.9039e-02,  2.0535e-01],\n",
       "         [ 4.9435e-02, -2.3369e-01, -2.4932e-02,  4.8874e-01],\n",
       "         [ 4.4761e-02, -4.2845e-01, -1.5157e-02,  7.7346e-01],\n",
       "         [ 3.6192e-02, -6.2336e-01,  3.1167e-04,  1.0613e+00],\n",
       "         [ 2.3725e-02, -4.2825e-01,  2.1538e-02,  7.6875e-01],\n",
       "         [ 1.5160e-02, -6.2366e-01,  3.6913e-02,  1.0681e+00],\n",
       "         [ 2.6867e-03, -4.2904e-01,  5.8276e-02,  7.8726e-01],\n",
       "         [-5.8942e-03, -6.2492e-01,  7.4021e-02,  1.0977e+00],\n",
       "         [-1.8392e-02, -4.3084e-01,  9.5975e-02,  8.2912e-01],\n",
       "         [-2.7009e-02, -6.2714e-01,  1.1256e-01,  1.1504e+00],\n",
       "         [-3.9552e-02, -4.3365e-01,  1.3556e-01,  8.9500e-01],\n",
       "         [-4.8225e-02, -6.3032e-01,  1.5346e-01,  1.2270e+00],\n",
       "         [-6.0831e-02, -4.3747e-01,  1.7801e-01,  9.8611e-01],\n",
       "         [-6.9581e-02, -2.4512e-01,  1.9773e-01,  7.5420e-01]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0]]),\n",
       " tensor([[-1.6072e-02, -2.2687e-01,  2.1840e-02,  3.3816e-01],\n",
       "         [-2.0609e-02, -3.2069e-02,  2.8604e-02,  5.2439e-02],\n",
       "         [-2.1251e-02, -2.2759e-01,  2.9652e-02,  3.5401e-01],\n",
       "         [-2.5802e-02, -3.2901e-02,  3.6732e-02,  7.0821e-02],\n",
       "         [-2.6460e-02,  1.6168e-01,  3.8149e-02, -2.1005e-01],\n",
       "         [-2.3227e-02,  3.5623e-01,  3.3948e-02, -4.9046e-01],\n",
       "         [-1.6102e-02,  1.6065e-01,  2.4139e-02, -1.8727e-01],\n",
       "         [-1.2889e-02, -3.4811e-02,  2.0393e-02,  1.1293e-01],\n",
       "         [-1.3585e-02,  1.6001e-01,  2.2652e-02, -1.7325e-01],\n",
       "         [-1.0385e-02, -3.5426e-02,  1.9187e-02,  1.2649e-01],\n",
       "         [-1.1094e-02,  1.5942e-01,  2.1716e-02, -1.6008e-01],\n",
       "         [-7.9054e-03,  3.5422e-01,  1.8515e-02, -4.4584e-01],\n",
       "         [-8.2103e-04,  1.5884e-01,  9.5981e-03, -1.4737e-01],\n",
       "         [ 2.3558e-03, -3.6417e-02,  6.6506e-03,  1.4832e-01],\n",
       "         [ 1.6275e-03, -2.3163e-01,  9.6170e-03,  4.4310e-01],\n",
       "         [-3.0052e-03, -3.6649e-02,  1.8479e-02,  1.5346e-01],\n",
       "         [-3.7382e-03,  1.5820e-01,  2.1548e-02, -1.3334e-01],\n",
       "         [-5.7411e-04, -3.7220e-02,  1.8881e-02,  1.6607e-01],\n",
       "         [-1.3185e-03, -2.3261e-01,  2.2203e-02,  4.6464e-01],\n",
       "         [-5.9707e-03, -3.7806e-02,  3.1496e-02,  1.7904e-01],\n",
       "         [-6.7268e-03,  1.5685e-01,  3.5076e-02, -1.0354e-01],\n",
       "         [-3.5898e-03,  3.5145e-01,  3.3006e-02, -3.8496e-01],\n",
       "         [ 3.4393e-03,  5.4609e-01,  2.5306e-02, -6.6705e-01],\n",
       "         [ 1.4361e-02,  7.4085e-01,  1.1965e-02, -9.5166e-01],\n",
       "         [ 2.9178e-02,  5.4557e-01, -7.0678e-03, -6.5524e-01],\n",
       "         [ 4.0090e-02,  3.5055e-01, -2.0173e-02, -3.6479e-01],\n",
       "         [ 4.7101e-02,  1.5572e-01, -2.7469e-02, -7.8539e-02],\n",
       "         [ 5.0215e-02, -3.8998e-02, -2.9039e-02,  2.0535e-01],\n",
       "         [ 4.9435e-02, -2.3369e-01, -2.4932e-02,  4.8874e-01],\n",
       "         [ 4.4761e-02, -4.2845e-01, -1.5157e-02,  7.7346e-01],\n",
       "         [ 3.6192e-02, -6.2336e-01,  3.1167e-04,  1.0613e+00],\n",
       "         [ 2.3725e-02, -4.2825e-01,  2.1538e-02,  7.6875e-01],\n",
       "         [ 1.5160e-02, -6.2366e-01,  3.6913e-02,  1.0681e+00],\n",
       "         [ 2.6867e-03, -4.2904e-01,  5.8276e-02,  7.8726e-01],\n",
       "         [-5.8942e-03, -6.2492e-01,  7.4021e-02,  1.0977e+00],\n",
       "         [-1.8392e-02, -4.3084e-01,  9.5975e-02,  8.2912e-01],\n",
       "         [-2.7009e-02, -6.2714e-01,  1.1256e-01,  1.1504e+00],\n",
       "         [-3.9552e-02, -4.3365e-01,  1.3556e-01,  8.9500e-01],\n",
       "         [-4.8225e-02, -6.3032e-01,  1.5346e-01,  1.2270e+00],\n",
       "         [-6.0831e-02, -4.3747e-01,  1.7801e-01,  9.8611e-01],\n",
       "         [-6.9581e-02, -2.4512e-01,  1.9773e-01,  7.5420e-01],\n",
       "         [-7.4483e-02, -4.4234e-01,  2.1281e-01,  1.1020e+00]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到一局游戏的数据\n",
    "def get_data():\n",
    "    states = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    next_states = []\n",
    "    overs = []\n",
    "\n",
    "    # 初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    # 玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        # 根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        # 执行动作,得到反馈\n",
    "        next_state, reward, over, _ = env.step(action)\n",
    "\n",
    "        # 记录数据样本\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        next_states.append(next_state)\n",
    "        overs.append(over)\n",
    "\n",
    "        # 更新游戏状态,开始下一个动作\n",
    "        state = next_state\n",
    "\n",
    "    #[b, 4]\n",
    "    states = torch.FloatTensor(states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    rewards = torch.FloatTensor(rewards).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    actions = torch.LongTensor(actions).reshape(-1, 1)\n",
    "    #[b, 4]\n",
    "    next_states = torch.FloatTensor(next_states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    overs = torch.LongTensor(overs).reshape(-1, 1)\n",
    "\n",
    "    return states, rewards, actions, next_states, overs\n",
    "\n",
    "\n",
    "get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    # 初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    # 记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    # 玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        # 根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        # 执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "        # 打印动画\n",
    "        if play and random.random() < 0.2:  # 跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.090483997483998, 8.690100963999999, 8.260044, 6.724, 4.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#优势函数\n",
    "def get_advantages(deltas):\n",
    "    advantages = []\n",
    "\n",
    "    #反向遍历deltas\n",
    "    s = 0.0\n",
    "    for delta in deltas[::-1]:\n",
    "        s = 0.98 * 0.95 * s + delta\n",
    "        advantages.append(s)\n",
    "\n",
    "    #逆序\n",
    "    advantages.reverse()\n",
    "    return advantages\n",
    "\n",
    "\n",
    "get_advantages(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8251,
     "status": "ok",
     "timestamp": 1650011468229,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "BQXVYW2T_DcQ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21.6\n",
      "50 199.3\n",
      "100 193.9\n",
      "150 195.6\n",
      "200 197.3\n",
      "250 200.0\n",
      "300 188.0\n",
      "350 200.0\n",
      "400 200.0\n",
      "450 200.0\n",
      "500 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    optimizer_td = torch.optim.Adam(model_td.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    # 玩N局游戏,每局游戏训练M次\n",
    "    for epoch in range(501):\n",
    "        # 玩一局游戏,得到数据\n",
    "        # states -> [b, 4]\n",
    "        # rewards -> [b, 1]\n",
    "        # actions -> [b, 1]\n",
    "        # next_states -> [b, 4]\n",
    "        # overs -> [b, 1]\n",
    "        states, rewards, actions, next_states, overs = get_data()\n",
    "\n",
    "        # 计算values和targets\n",
    "        # [b, 4] -> [b, 1]\n",
    "        values = model_td(states)\n",
    "\n",
    "        # [b, 4] -> [b, 1]\n",
    "        targets = model_td(next_states).detach()\n",
    "        targets = targets * 0.98\n",
    "        targets *= (1 - overs)\n",
    "        targets += rewards\n",
    "\n",
    "        # 计算优势,这里的advantages有点像是策略梯度里的reward_sum\n",
    "        # 只是这里计算的不是reward,而是target和value的差\n",
    "        # [b, 1]\n",
    "        deltas = (targets - values).squeeze(dim=1).tolist()\n",
    "        advantages = get_advantages(deltas)\n",
    "        advantages = torch.FloatTensor(advantages).reshape(-1, 1)\n",
    "\n",
    "        # 取出每一步动作的概率\n",
    "        # [b, 2] -> [b, 2] -> [b, 1]\n",
    "        old_probs = model(states)\n",
    "        old_probs = old_probs.gather(dim=1, index=actions)\n",
    "        old_probs = old_probs.detach()\n",
    "\n",
    "        # 每批数据反复训练10次\n",
    "        for _ in range(10):\n",
    "            # 重新计算每一步动作的概率\n",
    "            # [b, 4] -> [b, 2]\n",
    "            new_probs = model(states)\n",
    "            # [b, 2] -> [b, 1]\n",
    "            new_probs = new_probs.gather(dim=1, index=actions)\n",
    "            # new_probs = new_probs\n",
    "\n",
    "            # 求出概率的变化\n",
    "            # [b, 1] - [b, 1] -> [b, 1]\n",
    "            ratios = new_probs / old_probs\n",
    "\n",
    "            # 计算截断的和不截断的两份loss,取其中小的\n",
    "            # [b, 1] * [b, 1] -> [b, 1]\n",
    "            surr1 = ratios * advantages\n",
    "            # [b, 1] * [b, 1] -> [b, 1]\n",
    "            surr2 = torch.clamp(ratios, 0.8, 1.2) * advantages\n",
    "\n",
    "            loss = -torch.min(surr1, surr2)\n",
    "            loss = loss.mean()\n",
    "\n",
    "            # 重新计算value,并计算时序差分loss\n",
    "            values = model_td(states)\n",
    "            loss_td = loss_fn(values, targets)\n",
    "\n",
    "            # 更新参数\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer_td.zero_grad()\n",
    "            loss_td.backward()\n",
    "            optimizer_td.step()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(10)]) / 10\n",
    "            print(epoch, test_result)\n",
    "\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第9章-策略梯度算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
