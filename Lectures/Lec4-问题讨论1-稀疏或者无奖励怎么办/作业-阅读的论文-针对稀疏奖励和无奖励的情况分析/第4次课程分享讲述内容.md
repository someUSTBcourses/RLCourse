---
marp: true
# theme: uncover
theme: default
# _class: invert
footer: '深度强化学习！'
paginate: true
style: |
  section a {
      font-size: 100px;
      text-align: center;
  }

---
![img](..\images\models.png)

## **深度强化学习常用算法实践+奖励稀疏的问题解决**
---

## 目 录

#### 本节目标
* **深度强化学习常用算法实践**：
* **奖励稀疏/无奖励的方法**
---

## 深度强化学习常用算法实践

* 参考资料：动手学强化学习中-进阶篇     https: // hrl.boyuai.com/chapter/2/
  1. 基于值函数近似的深度强化学习算法实践  (吴紫燕)
     1. DQN算法   
     2. DQN改进算法
  2. 基于策略函数近似的深度强化学习算法实践 （刘琪）
     1.  第 9 章 策略梯度算法 
     2.  第 10 章 Actor-Critic 算法

---
# 深度强化学习常用算法实践

* 参考资料：动手学强化学习中-进阶篇     https: // hrl.boyuai.com/chapter/2/
  3. 实用算法1 （魏振洋）
     1. 第 11 章 TRPO 算法    
     2. 第 12 章 PPO 算法     
  4. 实用算法2   （刘新蕊）
     1. 第 13 章 DDPG 算法
     2. 第 14 章 SAC 算法

---

## 奖励稀疏/无奖励的做法
有篇[ 中文综述](./%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%A8%80%E7%96%8F%E5%A5%96%E5%8A%B1%E9%97%AE%E9%A2%98%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E6%9D%A8%E6%83%9F%E8%BD%B6.pdf)：综述了强化学习中奖励问题研究的总结
1. 如何利用已有数据
   1. Curiosity Driven：
      1. Curiosity-driven Exploration by Self-supervised Prediction - https: // arxiv.org/abs/1705.05363
   2. Hindsight Experience Replay（HER）：https: // arxiv.org/abs/1707.01495
   3. Priority Experience Replay：https:// arxiv.org/abs/1511.05952
  
---
## 奖励稀疏/无奖励的做法
有篇[ 中文综述](./%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%A8%80%E7%96%8F%E5%A5%96%E5%8A%B1%E9%97%AE%E9%A2%98%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E6%9D%A8%E6%83%9F%E8%BD%B6.pdf)：综述了强化学习中奖励问题研究的总结
2. 如何使用外部数据和信息
   1. Reward Shaping：论文-Reward Shaping in Episodic Reinforcement Learning
   2. Curriculum Learning: https:// openreview.net/pdf?id=Hk3mPK5gg
   3. 
   
---
## 奖励稀疏/无奖励的做法
有篇[ 中文综述](./%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%A8%80%E7%96%8F%E5%A5%96%E5%8A%B1%E9%97%AE%E9%A2%98%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E6%9D%A8%E6%83%9F%E8%BD%B6.pdf)：综述了强化学习中奖励问题研究的总结

1. 如何提高模型解决大状态空间大动作空间下的复杂问题的能力
   1. goal-conditioned reinforcement learning CGRL
   2. Learning Multi-Level Hierarchies with Hindsight
   3. Successor Entropy
   
---
