# 强化学习的库和平台有几何？
参考review：
1. https://farama.org/Announcing-The-Farama-Foundation
2. https://winder.ai/a-comparison-of-reinforcement-learning-frameworks-dopamine-rllib-keras-rl-coach-trfl-tensorforce-coach-and-more/
2. https://zhuanlan.zhihu.com/p/582396276 

## 1. CleanRL
If you use CleanRL in your work, please cite our technical [paper](https://www.jmlr.org/papers/v23/21-1342.html):

```bibtex
@article{huang2022cleanrl,
  author  = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and João G.M. Araújo},
  title   = {CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {274},
  pages   = {1--18},
  url     = {http://jmlr.org/papers/v23/21-1342.html}
}
```
## 2. PettingZoo是一个用于进行多代理强化学习研究的Python库，类似于多代理版的Gymnasium
文档：https://pettingzoo.farama.org/ 
```bibtex
@article{terry2021pettingzoo,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15032--15043},
  year={2021}
}
```

3. 支持分布式,多进程管理和调参 : [rllib](https://arxiv.org/abs/1712.09381)
   文档：https://docs.ray.io/en/latest/rllib/index.html 
   
4. [pymarl](https://github.com/oxwhirl/pymarl)
   
M. Samvelyan, T. Rashid, C. Schroeder de Witt, G. Farquhar, N. Nardelli, T.G.J. Rudner, C.-M. Hung, P.H.S. Torr, J. Foerster, S. Whiteson. The StarCraft Multi-Agent Challenge, CoRR abs/1902.04043, 2019.

```bibtex
@article{samvelyan19smac,
  title = {{The} {StarCraft} {Multi}-{Agent} {Challenge}},
  author = {Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philiph H. S. Torr and Jakob Foerster and Shimon Whiteson},
  journal = {CoRR},
  volume = {abs/1902.04043},
  year = {2019},
}
```
5. 支持多进程加速 :[rlpyt](https://arxiv.org/abs/1909.01500)
文档： https://github.com/astooke/rlpyt
```bibtex
@article{stooke2019rlpyt,
  title={rlpyt: A research code base for deep reinforcement learning in pytorch},
  author={Stooke, Adam and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1909.01500},
  year={2019}
}
```
