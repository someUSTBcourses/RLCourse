---
marp: true
# theme: uncover
theme: default
# _class: invert
footer: '强化学习前沿篇-动手学强化学习'
paginate: true
style: |
  section a {
      font-size: 100px;
      text-align: center;
  }

---


## **熟悉下常用强化学习算法，讨论下多智能体强化学习如何实现协作**

#### 本节目标
* **强化学习算法代码和综述总结**
* **多智能体强化学习研究重点**
* **多智能体强化学习协作-先看看**
---

## 强化学习算法代码和综述总结

* **1. 离线强化学习** ：动手学强化学习第18章(https:// hrl.boyuai.com/chapter/3/)
  * **综述论文**：只需要简单确认下综述主要提出的总结  
  * 论文名：Offline reinforcement learning: tutorial, review, and perspectives on open problems
* **2. 目标导向的强化学习** ：动手学强化学习第19章(https:// hrl.boyuai.com/chapter/3/)
  * **综述论文**：只需要简单确认下综述主要提出的总结
  * 论文名：Exploration via Hindsight Goal Generation
---
## 多智能体强化学习基本算法
### 解决可扩展问题
方法1；Mean-field
  3. Mean Field Multi-Agent Reinforcement Learning
  4. Mean-Field Controls with Q-learning for Cooperative MARL

方法2：Grid-wise
  5. Grid-Wise Control for Multi-Agent Reinforcement Learning in Video Game AI
  6. Off-the-Grid MARL: a Framework for Dataset Generation with Baselines for Cooperative Offline Multi-Agent Reinforcement Learning
---
## 多智能体强化学习基本算法
### 解决局部可观测问题 - 基于CTDE框架 
7. 多智能体MARL中的图 - Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced Local Value-Functions

值分解协作的算法
   8. 基本算法：总结多个
      * VDN ：Value-Decomposition Networks For Cooperative Multi-Agent Learning
      * QMIX： QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning
      * QTRAN：QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement learning

    基于协调图 ，实现动态的奖励分配
    9. Dynamic Coordination Graph for Cooperative Multi-Agent Reinforcement Learning


---
## 多智能体强化学习基本算法
### 解决局部可观测问题 - 基于CTDE框架

共享网络参数协作的算法（基于角色和任务）
 10. Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles2.   
 11. LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent Reinforcement Learning
 12. RODE: LEARNING ROLES TO DECOMPOSE MULTI-AGENT TASKS   张恒
 13. Hierarchical Cooperative Swarm Policy Learning with Role Emergence

---
## 多智能体强化学习基本算法
### 解决局部可观测问题 - 主动通信框架-communication  

训练过程中学习如何根据自身的局部观察来生成信息，或者来确定是否需要通信，与哪些智能体通信等。在执行过程中往往需要显式根据其余智能体传递的信息来进行决策

14. Learning Attentional Communication for Multi-Agent Cooperation
15. Effective Communications: A Joint Learning and Communication Framework for Multi-Agent Reinforcement Learning over Noisy Channels

---

---
## 多智能体强化学习基本算法
### 解决联合探索问题   

训练过程中学习如何根据自身的局部观察来生成信息，或者来确定是否需要通信，与哪些智能体通信等。在执行过程中往往需要显式根据其余智能体传递的信息来进行决策

16. MAVEN：MAVEN: Multi-Agent Variational Exploration
17. CDS：Celebrating Diversity in Shared Multi-Agent Reinforcement Learning
18. EMC: Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration
    好奇心驱动是使用内在奖励鼓励agent探索更陌生的状态。其中一类方法是基于状态预测误差的方法，将预测值与真值的距离作为内在奖励，可以鼓励探索.




---