{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf583f4-f64e-4e36-b30e-1817ec400243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     #Âè™ÈúÄË¶Å‰∏ãËΩΩnumpyÂ∫ìÂç≥ÂèØ\n",
    "import random\n",
    "import GridWorld_v2\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541a7035-6a60-43be-b2dd-b444c48646d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨úÔ∏è‚¨úÔ∏è‚¨úÔ∏è‚¨úÔ∏è‚¨úÔ∏è\n",
      "‚¨úÔ∏èüö´üö´‚¨úÔ∏è‚¨úÔ∏è\n",
      "‚¨úÔ∏è‚¨úÔ∏èüö´‚¨úÔ∏è‚¨úÔ∏è\n",
      "‚¨úÔ∏èüö´‚úÖüö´‚¨úÔ∏è\n",
      "‚¨úÔ∏èüö´‚¨úÔ∏è‚¨úÔ∏è‚¨úÔ∏è\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rows = 5      #ËÆ∞ÂæóË°åÊï∞ÂíåÂàóÊï∞ËøôÈáåË¶ÅÂêåÊ≠•Êîπ\n",
    "columns = 5\n",
    "\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(rows=rows, columns=columns, forbiddenAreaNums=8, targetNums=2, seed = 52,forbiddenAreaScore=-10)\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\".#\",\".T\"])             #ËµµËÄÅÂ∏à4-1ÁöÑ‰æãÂ≠ê\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\"##.T\",\"...#\",\"....\"])  #Èöè‰æøÂºÑÁöÑ‰æãÂ≠ê\n",
    "gridworld = GridWorld_v2.GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]) \n",
    "#gridworld = GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\"T.\"]) \n",
    "gridworld.show()\n",
    "\n",
    "\n",
    "value = np.zeros(rows*columns)       #ÂàùÂßãÂåñÂèØ‰ª•‰ªªÊÑèÔºå‰πüÂèØ‰ª•ÂÖ®0\n",
    "qtable = np.zeros((rows*columns,5))  #ÂàùÂßãÂåñÔºåËøôÈáå‰∏ªË¶ÅÊòØÂàùÂßãÂåñÁª¥Êï∞ÔºåÈáåÈù¢ÁöÑÂÜÖÂÆπ‰ºöË¢´Ë¶ÜÁõñÊâÄ‰ª•Êó†ÊâÄË∞ì\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9106e6ee-ba75-4ed4-987e-31f6192c58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_SARSA(gridworld:GridWorld_v2.GridWorld_v2,sarsaStep=5,epsilon=0.5,trajectorySteps=-1, learning_rate=0.001, final_epsilon=0.01, num_episodes=600, gamma = 0.9)->GridWorld_v2.GridWorld_v2:\n",
    "    \"\"\"\n",
    "    ËøôÊòØn-step-SARSAÁÆóÊ≥ï\n",
    "\n",
    "    Parameters:\n",
    "    sarsaStep (int): ÂØπÂ∫în-step-sarsaÈÇ£‰∏™nÁöÑÂ§ßÂ∞è\n",
    "    trajectorySteps (int): ÂØªË∑ØÁöÑËΩ®ËøπÈïøÂ∫¶ÔºåÂ¶ÇÊûúÊòØ-1ÔºåÂàô‰∏∫ÂØªÂà∞ÁõÆÁöÑÂàôÂÅúÊ≠¢ÔºåÂê¶ÂàôÂèÇÊï∞Âç≥‰∏∫trajectoryÈïøÂ∫¶\n",
    "    learning_rate (float): Â≠¶‰π†ÁéáÔºåÁî®‰∫éË∞ÉËäÇTD-target\n",
    "    final_epsilon (float): epsilon-greedyÁöÑÊ†∏ÂøÉÂèÇÊï∞Ôºå0~1ÁöÑÊµÆÁÇπÊï∞ÔºåÂÖ∂‰∏≠1ÂàôË°®Á§∫ÂΩìÂâçstateÊâÄÊúâÂÜ≥Á≠ñÊ¶ÇÁéá‰∏ÄÊ†∑Ôºå0ÂàôË°®Á§∫ÂÜ≥Á≠ñÊ≤°Êúâ‰ªª‰ΩïÁöÑÈöèÊú∫ÊÄß\n",
    "    num_episodes (int): Ë°®Á§∫Ê®°ÂûãËø≠‰ª£Ê¨°Êï∞\n",
    "    gamma (float): ËøëËßÜËøúËßÜÁ®ãÂ∫¶\n",
    "\n",
    "    Returns:\n",
    "    GridWorld_v2.GridWorld_v2: ÊääÊ®°ÂûãËøîÂõûÂõûÂéª\n",
    "    \"\"\"\n",
    "    \n",
    "    state_value = np.zeros((rows * columns))\n",
    "    action_value = np.zeros((rows * columns, 5))\n",
    "    policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "    for episode in range(num_episodes):\n",
    "        #Ê∏ÖÈô§ËæìÂá∫ÔºåÂèØ‰ª•Êõ¥Â•ΩÁöÑÂ±ïÁ§∫Á≠ñÁï•\n",
    "        time.sleep(0.2)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(\"episode\",f\"{episode}/{num_episodes}\")\n",
    "        if(epsilon > final_epsilon) :\n",
    "            epsilon -= 0.001\n",
    "        else:\n",
    "            epsilon = final_epsilon\n",
    "\n",
    "        # p1ÊòØÁõÆÊ†áÊñπÂêëÁöÑÊ¶ÇÁéáÔºåp0ÊòØÂè¶Â§ñÂõõ‰∏™ÊñπÂêëÁöÑÊ¶ÇÁéá\n",
    "        p1 = 1-epsilon * (4/5)\n",
    "        p0 = epsilon/5\n",
    "        d = {1:p1, 0:p0}\n",
    "        # policy_epsilonÊòØpolicyÂèñepsilon-greedyÁöÑÊ¶ÇÁéáÂÜ≥Á≠ñ\n",
    "        print(\"p1\",p1,\"p0\",p0)\n",
    "        policy_epsilon = np.vectorize(d.get)(policy)\n",
    "\n",
    "        #cntÊï∞ÁªÑÁî®Êù•Ê£ÄÊü•ÊØè‰∏™stateÊúâÂ§öÂ∞ëÊ¨°ËÆøÈóÆ\n",
    "        cnt = [0 for i in range(25)]\n",
    "        \n",
    "        initState=10\n",
    "        initAction=random.randint(0,4)  \n",
    "\n",
    "        if trajectorySteps==-1:\n",
    "            stop_when_reach_target = True\n",
    "        Trajectory = gridworld.getTrajectoryScore(nowState=initState, \n",
    "                                                  action=initAction, \n",
    "                                                  policy=policy_epsilon, \n",
    "                                                  steps=trajectorySteps, \n",
    "                                                  stop_when_reach_target=True)\n",
    "        for i in range(sarsaStep):\n",
    "            Trajectory.append((17,4,1,17,4)) #ËÆ©‰ªñÊúÄÂêéËá™ËΩ¨‰∏Ä‰∏ã\n",
    "        print(\"trajectorySteps\",len(Trajectory))\n",
    "        \n",
    "\n",
    "        \n",
    "        # Ê≥®ÊÑèËøôÈáåÁöÑËøîÂõûÂÄºÊòØÂ§ßÂ∞è‰∏∫(trajectorySteps+1)ÁöÑÂÖÉÁªÑÂàóË°®ÔºåÂõ†‰∏∫ÊääÁ¨¨‰∏Ä‰∏™Âä®‰Ωú‰πüÂä†ÂÖ•ËøõÂéª‰∫Ü\n",
    "        \n",
    "        steps = len(Trajectory)\n",
    "        if steps>trajectorySteps:\n",
    "            continue\n",
    "        g = 1\n",
    "        reward = 0\n",
    "        for k in range(0, steps, 1):\n",
    "            tmpstate, tmpaction, tmpscore, nextState, nextAction  = Trajectory[k]\n",
    "            reward += tmpscore * g\n",
    "            g *= gamma\n",
    "        print(\"Trajectory_score\", reward)\n",
    "\n",
    "\n",
    "        \n",
    "        for k in range(0, steps - sarsaStep + 1, 1):\n",
    "            #StateÔºåActionÔºåRewardÔºåNextStateÔºåNextAction\n",
    "            cnt[Trajectory[k][0]] += 1\n",
    "            #n-step-SARSA \n",
    "            nowState,nowAction = -1,-1\n",
    "            g = 1\n",
    "            reward = 0\n",
    "            for i in range(sarsaStep):\n",
    "                #StateÔºåActionÔºåRewardÔºåNextStateÔºåNextAction\n",
    "                tmpstate, tmpaction, tmpscore, nextState, nextAction  = Trajectory[k+i]\n",
    "                if nowState == -1:\n",
    "                    nowState, nowAction = tmpstate, tmpaction\n",
    "                reward += tmpscore * g\n",
    "                g *= gamma\n",
    "            reward += g*action_value[nextState][nextAction]\n",
    "            \n",
    "            TD_error = action_value[nowState][nowAction] - reward\n",
    "            action_value[nowState][nowAction] -= learning_rate * TD_error\n",
    "\n",
    "        # for k in range(steps - sarsaStep+1, steps, 1):\n",
    "        #     # print(k)\n",
    "        #     #StateÔºåActionÔºåRewardÔºåNextStateÔºåNextAction\n",
    "        #     tmpstate, tmpaction, tmpscore, nextState, nextAction  = Trajectory[k]\n",
    "        #     cnt[tmpstate] += 1\n",
    "        #     TD_error = action_value[tmpstate][tmpaction] - (tmpscore + gamma * action_value[nextState][nextAction])\n",
    "        #     action_value[tmpstate][tmpaction] -= learning_rate * TD_error\n",
    "\n",
    "\n",
    "        # policy improvement\n",
    "        policy = np.eye(5)[np.argmax(action_value,axis=1)]  #qtableÁöÑÊúÄ‰ºòÂÄº‰Ωú‰∏∫Êõ¥Êñ∞Á≠ñÁï•ÔºåÂπ∂Áî®Áã¨ÁÉ≠Á†ÅÊù•Ë°®Á§∫\n",
    "        policy_epsilon = np.vectorize(d.get)(policy)\n",
    "    \n",
    "        #ËæìÂá∫ÊØè‰∏™stateÁöÑËÆøÈóÆÊ¨°Êï∞\n",
    "        print(np.array(cnt).reshape(5,5)) \n",
    "\n",
    "        state_value = np.sum(policy_epsilon * action_value,axis=1)\n",
    "        mean_state_value = np.sum(policy_epsilon * action_value,axis=1).mean()\n",
    "        \n",
    "        gridworld.showPolicy(policy)\n",
    "        print(np.round(action_value,decimals=3).reshape(-1,5))\n",
    "        print(np.round(state_value,decimals=4).reshape(5,5))\n",
    "        print(\"mean_state_value\", mean_state_value)\n",
    "\n",
    "    return gridworld\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea719e1c-f5af-41e2-b17d-bf551e834593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 399/400\n",
      "p1 0.9200000000000003 p0 0.019999999999999928\n",
      "trajectorySteps 31\n",
      "Trajectory_score 2.7739776150757676\n",
      "[[ 1  1  1  1  1]\n",
      " [ 1  0  0  0  1]\n",
      " [15  0  0  0  1]\n",
      " [ 0  0  2  0  1]\n",
      " [ 0  0  1  1  1]]\n",
      "‚û°Ô∏è‚û°Ô∏è‚û°Ô∏è‚û°Ô∏è‚¨áÔ∏è\n",
      "‚¨ÜÔ∏è‚è¨‚è©Ô∏è‚¨ÜÔ∏è‚¨áÔ∏è\n",
      "üîÑ‚¨ÖÔ∏è‚è¨‚¨ÜÔ∏è‚¨áÔ∏è\n",
      "‚¨ÜÔ∏è‚è©Ô∏è‚úÖ‚è™‚¨áÔ∏è\n",
      "üîÑ‚è©Ô∏è‚¨ÜÔ∏è‚¨ÖÔ∏è‚¨ÖÔ∏è\n",
      "[[-0.927 -0.736 -0.739 -0.869 -0.748]\n",
      " [-0.546 -0.419 -1.198 -0.467 -0.464]\n",
      " [-0.423 -0.18  -0.905 -0.205 -0.201]\n",
      " [-0.472 -0.355 -0.368 -0.36  -0.366]\n",
      " [-0.769 -0.646 -0.375 -0.39  -0.739]\n",
      " [-0.6   -1.989 -0.611 -1.17  -0.637]\n",
      " [-0.178 -0.346 -0.177 -0.201 -0.323]\n",
      " [-0.113 -0.104 -0.176 -0.182 -0.209]\n",
      " [-0.151 -0.16  -0.234 -1.026 -0.188]\n",
      " [-0.402 -0.523 -0.386 -0.528 -0.453]\n",
      " [-0.759 -0.951 -0.756 -1.001 -0.752]\n",
      " [-0.655 -0.504 -0.465 -0.317 -0.321]\n",
      " [-0.122 -0.061  0.051 -0.063 -0.266]\n",
      " [-0.15  -0.151 -0.379 -0.589 -0.163]\n",
      " [-0.341 -0.413 -0.332 -0.5   -0.339]\n",
      " [-0.594 -1.291 -0.596 -0.843 -0.602]\n",
      " [-0.072  0.252 -0.178 -0.046 -0.203]\n",
      " [-0.217 -0.112  0.071 -0.195  2.063]\n",
      " [-0.011 -0.028 -0.012  0.064 -0.068]\n",
      " [-0.167 -0.202 -0.148 -0.581 -0.167]\n",
      " [-0.514 -0.751 -0.573 -0.536 -0.513]\n",
      " [-0.162 -0.032 -0.1   -0.063 -0.132]\n",
      " [ 0.369 -0.008 -0.029 -0.192 -0.025]\n",
      " [-0.19  -0.067 -0.093  0.081 -0.064]\n",
      " [-0.161 -0.159 -0.188 -0.065 -0.169]]\n",
      "[[-0.7425 -0.4387 -0.2005 -0.358  -0.3957]\n",
      " [-0.6398 -0.184  -0.1093 -0.1715 -0.3935]\n",
      " [-0.7614 -0.3305  0.0366 -0.1639 -0.3371]\n",
      " [-0.6131  0.2218  1.8893  0.0568 -0.1585]\n",
      " [-0.5197 -0.0383  0.334   0.0659 -0.0736]]\n",
      "mean_state_value -0.16100571896329888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GridWorld_v2.GridWorld_v2 at 0x7f3875a84910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_SARSA(gridworld,sarsaStep = 3, trajectorySteps=5000,final_epsilon=0.1,num_episodes = 400,gamma = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8891dec-e970-47b6-b65e-63c2ec907bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 599/600\n",
      "p1 0.992 p0 0.002\n",
      "trajectorySteps 20001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GridWorld_v2.GridWorld_v2 at 0x1c8e0ecf760>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_SARSA(gridworld,sarsaStep = 2, trajectorySteps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cf4d09fc-f037-44fd-acea-c1765cf78f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 0.81, 0.72, 0.65, 0.59, 0.53, 0.47, 0.43, 0.38, 0.34, 0.31, 0.28, 0.25, 0.22, 0.2]\n"
     ]
    }
   ],
   "source": [
    "g = 1\n",
    "res = []\n",
    "for i in range(15):\n",
    "    g *= 0.9\n",
    "    res.append(g*100//1/100)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9342aef4-7e29-4a05-acce-214b26f05b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91, 0.9, 0.89, 0.88, 0.87, 0.86, 0.86]\n"
     ]
    }
   ],
   "source": [
    "g = 1\n",
    "res = []\n",
    "for i in range(15):\n",
    "    g *= 0.99\n",
    "    res.append(g*100//1/100)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c8f9d-3531-4614-9b83-933a97f7b1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
