{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "843482d8-4944-4de7-9ea1-62a089cb0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     #只需要下载numpy库即可\n",
    "import random\n",
    "import GridWorld_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "864c3b7f-fea4-4caa-8ae5-dce3516b4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️🚫🚫⬜️⬜️\n",
      "⬜️⬜️🚫⬜️⬜️\n",
      "⬜️🚫✅🚫⬜️\n",
      "⬜️🚫⬜️⬜️⬜️\n",
      "➡️⬆️🔄⬆️⬆️\n",
      "➡️⏪⏬⬇️⬅️\n",
      "➡️⬅️⏬🔄➡️\n",
      "⬆️⏫️✅⏪⬆️\n",
      "🔄🔄⬇️🔄⬆️\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9   #折扣因子，越接近0越近视\n",
    "\n",
    "rows = 5      #记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(rows=rows, columns=columns, forbiddenAreaNums=8, targetNums=2, seed = 52,forbiddenAreaScore=-10)\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\".#\",\".T\"])             #赵老师4-1的例子\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\"##.T\",\"...#\",\"....\"])  #随便弄的例子\n",
    "gridworld = GridWorld_v2.GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]) \n",
    "#gridworld = GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\"T.\"]) \n",
    "gridworld.show()\n",
    "\n",
    "\n",
    "value = np.zeros(rows*columns)       #初始化可以任意，也可以全0\n",
    "qtable = np.zeros((rows*columns,5))  #初始化，这里主要是初始化维数，里面的内容会被覆盖所以无所谓\n",
    "\n",
    "\n",
    "# np.random.seed(50)\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.showPolicy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83befbda-7855-44ca-b31f-47cf5a074cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3689097d-fac9-45af-aa1a-a883eff8837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.00551809e-04 -4.00035284e-03 -1.92287192e-01 -8.99659139e+00\n",
      "  -9.98879557e+00]\n",
      " [-2.20293206e-03 -4.29060559e-03 -1.00645800e+00 -8.09714020e+00\n",
      "  -9.97511497e+00]\n",
      " [-3.18021642e-04 -2.42876949e-03  9.99068284e+00 -4.00144532e-04\n",
      "   6.47784629e+00]\n",
      " [-4.01056575e-04  9.98777194e+00  9.90913692e+00  9.99468079e+00\n",
      "   7.19744115e+00]\n",
      " [-2.55517917e-03 -7.78886104e-03  9.96022892e+00  8.88578440e+00\n",
      "   7.99718417e+00]]\n",
      "➡️⬅️🔄➡️➡️\n",
      "🔄⏬⏬⬆️➡️\n",
      "➡️⬅️⏬⬆️⬇️\n",
      "⬇️⏩️✅⏪⬇️\n",
      "⬆️⏩️⬆️⬅️⬅️\n",
      "1.6847833442618705\n"
     ]
    }
   ],
   "source": [
    "#通过采样的方法计算action value，model free的话意味着不知道整个gridworld的概率了，所以不能直接套贝尔曼方程迭代求解\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.show()\n",
    "gridworld.showPolicy(policy)\n",
    "print(\"random policy\")\n",
    "\n",
    "\n",
    "trajectorySteps = 20000\n",
    "epsilon = 0.1 #0.2\n",
    "qtable = np.zeros((rows*columns,5))    #生成Qtable，也就是action-value-table\n",
    "\n",
    "num_episodes = 200\n",
    "for episode in range(num_episodes):\n",
    "    # \n",
    "    if(epsilon > 0.001) :\n",
    "        epsilon -= 0.001\n",
    "    else:\n",
    "        epsilon = 0.001\n",
    "        \n",
    "    p1 = 1-epsilon * (4/5)\n",
    "    p0 = epsilon/5\n",
    "    # trajectorySteps = int(20+epsilon*1000)\n",
    "    print(\"trajectorySteps\",trajectorySteps)\n",
    "    print(f\"epision:{epsilon}, p1:{p1}, p0:{p0}\")\n",
    "    \n",
    "    d = {1:p1, 0:p0}\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "    \n",
    "    i = random.randint(0,24)  #初始状态\n",
    "    j = random.randint(0,4)\n",
    "\n",
    "    cnt = [0 for i in range(25)]\n",
    "    qtable_rewards = [[0 for j in range(5)] for i in range(rows * columns)] \n",
    "    qtable_nums =    [[0 for j in range(5)] for i in range(rows * columns)]\n",
    "    Trajectory = gridworld.getTrajectoryScore(nowState=i, action=j, policy=policy_epsilon, steps=trajectorySteps)\n",
    "    clear_output(wait=True)\n",
    "    # 注意这里的返回值是大小为(trajectorySteps+1)的元组列表，因为把第一个动作也加入进去了\n",
    "    score = 0\n",
    "    for k in range(trajectorySteps,-1,-1):\n",
    "        tmpstate, tmpaction, tmpscore, _, __  = Trajectory[k]\n",
    "        cnt[tmpstate] += 1\n",
    "        score = score*gamma + tmpscore  #细节从后往前优化算法\n",
    "        \n",
    "        qtable_rewards[tmpstate][tmpaction] += score\n",
    "        qtable_nums[tmpstate][tmpaction] += 1\n",
    "        qtable[tmpstate][tmpaction] = qtable_rewards[tmpstate][tmpaction] / qtable_nums[tmpstate][tmpaction]\n",
    "\n",
    "    values = []\n",
    "    for i in range(25):\n",
    "        v = 0\n",
    "        for j in range(5):\n",
    "            v += policy_epsilon[i][j] * qtable[i][j]\n",
    "        values.append(v)\n",
    "    print(np.array(values).reshape(5,5))\n",
    "    \n",
    "    # print(qvalue.reshape(5,5))\n",
    "    gridworld.showPolicy(policy)\n",
    "    print(np.array(values).mean())\n",
    "    \n",
    "    \n",
    "    policy = np.eye(5)[np.argmax(qtable,axis=1)]  #qtable的最优值作为更新策略，并用独热码来表示\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "        \n",
    "    # print(np.array(cnt).reshape(5,5))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1ce49-9b72-44a9-9413-c811bb04f577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
